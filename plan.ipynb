{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce090555",
   "metadata": {
    "id": "ce090555"
   },
   "source": [
    "Индивидуальный проект: **Популярность музыки в сервисе Spotify за 2014-2022**\n",
    "\n",
    "Автор: **Куготов Алим Заурович**\n",
    "\n",
    "Проверяющий: **Нечаев Илья Андреевич**\n",
    "\n",
    "Ссылка на датасет: https://www.kaggle.com/datasets/jfreyberg/spotify-chart-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de16fd54",
   "metadata": {
    "id": "de16fd54"
   },
   "source": [
    "### Примерный план (подстроить план под вашу задачу)\n",
    "1. Цель и задачи исследования\n",
    "2. Описание набора данных\n",
    "3. Разведочный анализ данных (англ. exploratory data analysis, EDA) + визуализация\n",
    "4. Генерация и селекция признаков + нормализация\n",
    "5. Исключение аномалий, заполнение пропусков в данных и.т.д.\n",
    "6. Очистка данных от шума\n",
    "7. Выбор метода/алгоритма, модели, архитектуры (для НС)\n",
    "8. Настройка гиперпараметров (для НС), выбор параметров метода/алгоритма\n",
    "9. Выбор метрики оценки качества (RMSE, R^2)\n",
    "10. Генерация наборов для обучения, тестирования и валидации\n",
    "11. Развертывание и работа модели, визуализация результатов\n",
    "12. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f24c93",
   "metadata": {
    "id": "51f24c93"
   },
   "source": [
    "## 1. Цель и задачи исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366ec07",
   "metadata": {
    "id": "5366ec07"
   },
   "source": [
    "Своей целью ставлю исследование индустрии музыки за последний десяток лет - выявить самых популярных артистов, альбомы, жанры. \n",
    "\n",
    "Сам же годами слушаю примерно одно и то же: \n",
    "- рок 60-х ([the doors](https://music.yandex.ru/artist/29060), \n",
    "[the rolling stones](https://music.yandex.ru/artist/6601), \n",
    "[led zeppelin](https://music.yandex.ru/artist/68227)) - любовь к жанру привил мне отец;\n",
    "\n",
    "- электронику 90х ([massive atack](https://music.yandex.ru/artist/89677), \n",
    "[moby](https://music.yandex.ru/artist/27154), \n",
    "[depeche mode](https://music.yandex.ru/artist/36810), \n",
    "[enigma](https://music.yandex.ru/artist/89677)), что встречается во многих культовых фильмах и сериалах: \n",
    "например, в [клане сопрано](https://vk.com/video/@alim_kugot?z=video-120075923_456242536%2Fpl_163408758_-2);\n",
    "\n",
    "\n",
    "За последние лет 5 открыл для себя только русский/казахский хип-хоп, который зацепил меня своей дерзостью, прямотой и текстами. Эта индустрия построилась с нуля, отражает самые разные проблемы (финансовые, социальные, семейные). Их мотивы стали мне близки с переездом и взрослением.\n",
    "\n",
    "Резуюмируя, музыка и культура - отражают настроение в обществе и душевные состояния человека. Мне интересно понять, как они менялось со временем, какие жанры приобретали популярность, почему тот или иной артист стал знаменитым именно в это время, почему стал популярным именно этот альбом (ведь исполнитель, скорее всего, писал похожие ранее). \n",
    "Здесь я это и хотел бы выяснить"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b965b9",
   "metadata": {
    "id": "57b965b9"
   },
   "source": [
    "## 2. Описание набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377565b",
   "metadata": {
    "id": "b377565b"
   },
   "source": [
    "Данные взяты из: [kaggle/datasets/spotify_charts_link](https://www.kaggle.com/datasets/jfreyberg/spotify-chart-data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c68209",
   "metadata": {
    "id": "05c68209"
   },
   "source": [
    "### Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee1cfc9",
   "metadata": {
    "id": "5ee1cfc9"
   },
   "source": [
    "Датасет представлен в виде единственного csv-файла: ***data/charts.csv***.\n",
    "\n",
    "Данные собирались на основе популярности аудио-треков в чартах spotify - на основе открытого Spotify API, как пишет сам автор датасета: \n",
    "*The dataset is obtained from https://kworb.net/spotify/ and the official Spotify API.*.\n",
    "\n",
    "Датасет собирался для исследования и анализа индустрии музыки, для выявления новых трендов, популярности жанров и тд:\n",
    "- Выборка включает 626475  записей и 10 признаков (строки и столбцы соответственно).\n",
    "- Целевая переменная **position** - позиция в чарте (в зависимости от страны)\n",
    "\n",
    "- Номинальные переменные:\n",
    "    - **track_id#1** - уникальный id в spotify;\n",
    "    \n",
    "- Количественные переменные:\n",
    "    - **date#3** — дата появление в чарте;\n",
    "    - **position#4** - позиция в чарте;\n",
    "    - **streams#5** - количество stream-ов при появлении в чарте;\n",
    "    - **duration#8** - \n",
    "    - **название признака#N** — что обозначает этот признак;\n",
    "    \n",
    "- Категориальные переменные:\n",
    "    - **name#1** — название трека;\n",
    "    - **country#2** - код страны, в которой появлялась песня в чарте;\n",
    "    - **artists#6** — авторы (исполнители) песни;\n",
    "    - **artist_genres#7** -жанры, в которых исполнители выступают;\n",
    "\n",
    "- Бинарные переменные: \n",
    "    - **explicit#9** - возрастное ограничение (есть/нет) \n",
    "   \n",
    "<br>\n",
    "\n",
    "> Не планирую использовать признаки: ***track_id*** (сурогатный ключ из базы данных нам не нужен); ***streams*** (не представляю какую полезную информацию признак в себе несёт)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A1rXFIN0vQQk",
   "metadata": {
    "id": "A1rXFIN0vQQk"
   },
   "source": [
    "##  3. Разведочный анализ данных (англ. exploratory data analysis, EDA) + визуализация\n",
    "\n",
    "[Что такое EDA?](https://en.wikipedia.org/wiki/Exploratory_data_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9395df",
   "metadata": {
    "id": "ba9395df"
   },
   "source": [
    "- выгрузка данных\n",
    "- визуализация\n",
    "- взаимодействие между параметрами (корреляция и прочее)\n",
    "- проверка на нормальность\n",
    "- закономерности, \"инсайты\", особенности данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8hu3iLkHRQpk",
   "metadata": {
    "id": "8hu3iLkHRQpk"
   },
   "source": [
    "## 4. Генерация и селекция признаков + нормализация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LiMreLEvvlKQ",
   "metadata": {
    "id": "LiMreLEvvlKQ"
   },
   "source": [
    "[Feature selection & Feature generation](https://www.bigdataschool.ru/blog/data-preparation-operations.html)\n",
    "\n",
    "Для задач с временными рядами: https://github.com/blue-yonder/tsfresh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VBy34nqVRpee",
   "metadata": {
    "id": "VBy34nqVRpee"
   },
   "source": [
    "## 5. Исключение аномалий, заполнение пропусков в данных и.т.д.\n",
    "\n",
    "Используем критерии 3 сигма, гистограммы, ящики с усами и.т.д.:\n",
    " [Anomaly Detection](https://alexanderdyakonov.wordpress.com/2017/04/19/%D0%BF%D0%BE%D0%B8%D1%81%D0%BA-%D0%B0%D0%BD%D0%BE%D0%BC%D0%B0%D0%BB%D0%B8%D0%B9-anomaly-detection/)\n",
    " [Подготовка датасета](https://proglib.io/p/moem-dataset-rukovodstvo-po-ochistke-dannyh-v-python-2020-03-27)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3pPFrp1nR52C",
   "metadata": {
    "id": "3pPFrp1nR52C"
   },
   "source": [
    "## 6. Очистка данных от шума\n",
    "\n",
    "Можно использовать любые алгоритмы очистки от шума (сигналы: на основе [Empirical Mode Decomposition](https://en.wikipedia.org/wiki/Hilbert%E2%80%93Huang_transform), [Intrinsic Time-Scale Decomposition](https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.2006.1761), изображения: [Non-Local Means](https://en.wikipedia.org/wiki/Non-local_means), [Kuwahara](https://subsurfwiki.org/wiki/Kuwahara_filter), [Symmetric Nearest Neighbour Filter](https://subsurfwiki.org/wiki/Symmetric_nearest_neighbour_filter)) и другие."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lxHOND4CSANI",
   "metadata": {
    "id": "lxHOND4CSANI"
   },
   "source": [
    "## 7. Выбор метода/алгоритма, модели, архитектуры (для НС)\n",
    "\n",
    "- Выбрать 2 типа модели:\n",
    "\n",
    "    - Одну baseline модель — это может быть `линейная регрессия` (для задачи регрессии), `k-nearest neighbour` для задачи классификации, `k-means` для кластеризации\n",
    "\n",
    "    - Вторую посложнее — для задачи регрессии, random forest, gradient-boosted tree ([XGBoost & CatBoost](https://towardsdatascience.com/catboost-vs-lightgbm-vs-xgboost-c80f40662924)) и другие. Дополнительно для временных рядов: SARIMAX, [Prophet](https://facebook.github.io/prophet/docs/quick_start.html#python-api). Для задачи классификации: logistic regression, decision tree, random forest, gradient-boosted tree ([XGBoost & CatBoost](https://towardsdatascience.com/catboost-vs-lightgbm-vs-xgboost-c80f40662924)), multilayer perceptron и другие.\n",
    "\n",
    "  Если у Вас задачка с изображениями — необходимо выбрать [простую уже обученную ИНС](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FIkfLnalX3hy",
   "metadata": {
    "id": "FIkfLnalX3hy"
   },
   "source": [
    "## 8. Настройка гиперпараметров (для НС), выбор параметров метода/алгоритма\n",
    "\n",
    "- Самый естественный способ организовать подбор гиперпараметров — сделать перебор по сетке (`Grid Search`):\n",
    "\n",
    "  - для каждого гиперпараметра фиксируется несколько значений;\n",
    "  - перебираются все комбинации значений различных гиперпараметров, на каждой из этих комбинаций модель обучается и тестируется;\n",
    "  - выбирается комбинация, на которой модель показывает лучшее качество;\n",
    "  - есть много библиотечных функций для [Grid Search](https://pythonpip.ru/osnovy/poisk-po-setke-python), например [тут](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JZ9cDq6wX6sa",
   "metadata": {
    "id": "JZ9cDq6wX6sa"
   },
   "source": [
    "## 9. Выбор метрики оценки качества (RMSE, R^2)\n",
    "\n",
    "- Выбрать метрики (обосновать выбор).\n",
    "\n",
    "Важно внимательно подходить к выбору метрики: в случае с несбалансированными классами классификатор может все объекты записать в класс, который представлен большим количеством объектов, а такая метрика как accuracy (доля объектов, для которых мы правильно предсказали класс для задачи классификации) будет все такой же высокой.\n",
    "\n",
    "Для регрессии (MSE, RMSE, MAE, R^2 и другие). Используйте RMSE, если хотите, чтобы большие ошибки были более значительными.\n",
    "Более подробно [по ссылке](https://ml-handbook.ru/chapters/model_evaluation/intro).\n",
    "\n",
    "\n",
    "Задачи с кластеризацией (рекомендательные системы) сложнее проверить экспериментально. Один из способов сделать это — взять часть ваших данных и спрятать их. Когда ваша модель построена, используйте её, чтобы предсказать рекомендации для скрытых данных и посмотреть, как они выстраиваются. (добавлю позже ссылку).\n",
    "\n",
    "- Определить какое значение будет успешным для вашей задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RbtxGcQvX8Ey",
   "metadata": {
    "id": "RbtxGcQvX8Ey"
   },
   "source": [
    "## 10. Генерация наборов для обучения, тестирования и валидации\n",
    "\n",
    "- Разделение выборки на обучающую и тестовую (70/30 или 80/20).\n",
    "    - Отложить тестовую выборку до финального теста\n",
    "    - Валидационная часть может быть выделена автоматически при кросс-валидации\n",
    "\n",
    "\n",
    "- Провести кросс-валидацию. Кросс-валидация может быть нужна в случаях, если данных мало или мы не хотим зависеть от конкретного выбора валидационного множества. \n",
    "\n",
    "   - Например, можно использовать метод `k-Fold`\n",
    "\n",
    "  - Кросс-валидация для временных рядов посложнее, так как данные не должны пересекаться по времени: тренировочные данные должны идти до валидационных, а валидационные — до тестовых"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VgxHtJo0X9Ki",
   "metadata": {
    "id": "VgxHtJo0X9Ki"
   },
   "source": [
    "## 11. Развертывание и работа модели, визуализация результатов\n",
    "\n",
    "После того, как выбраны лучшие гиперпараметры модели, необходимо обучить модель на данных параметрах и протестировать на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GErABncWSV-B",
   "metadata": {
    "id": "GErABncWSV-B"
   },
   "source": [
    "## 12. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N-Nx-I_i2CyZ",
   "metadata": {
    "id": "N-Nx-I_i2CyZ"
   },
   "source": [
    "Предупреждая возможный холивар — структура данного фреймворка не истина в \n",
    "последней инстанции, есть много других способов структурировать свои \n",
    "пайплайны — это всего лишь один из них."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_77lSlpX2as2",
   "metadata": {
    "id": "_77lSlpX2as2"
   },
   "source": [
    "- EDA (exploratory data analysis). Тут надо сделать замечание — на Kaggle есть специально обученные люди :), которые в каждом соревновании пилят сногсшибательные EDA кернелы. Переплюнуть их у вас вряд-ли получится, но понимать, как можно смотреть на данные все-равно придется, поскольку в боевых задачах этим специально обученным человеком будете вы. Поэтому изучаем подходы, расширяем наши библиотеки.\n",
    "- Data Cleaning — все, что касается очистки данных. Выбросы, пропуски, и т.д.\n",
    "- Data preparation — все, что касается подготовки данных для модели. Несколько блоков:\n",
    "  - Общий\n",
    "  - Для регрессий/нейронных сетей\n",
    "  - Для деревьев\n",
    "  - Специальный (временные ряды, картинки, FM/FFM)\n",
    "  - Текст (Vectorizers, TF-IDF, Embeddings)\n",
    "- Models\n",
    "  - Linear models\n",
    "  - Tree models\n",
    "  - Neural Networks\n",
    "  - Exotic (FM/FFM)\n",
    "- Feature selection\n",
    "- Hyperparameters search\n",
    "- Ensemble"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "51f24c93",
    "57b965b9",
    "GErABncWSV-B"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
